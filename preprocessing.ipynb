{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9328f372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "from IPython.display import clear_output\n",
    "import requests\n",
    "import spacy\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download(\"stopwords\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "08f7941c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_progress(progress):\n",
    "    bar_length = 50\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "\n",
    "    block = int(round(bar_length * progress))\n",
    "\n",
    "    clear_output(wait = True)\n",
    "    text = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "320a9803",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('de_core_news_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "940d80c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text, stopwords):\n",
    "    text = text.lower()\n",
    "    print(\"lowered\")\n",
    "    \n",
    "    # remove \"&nbsp\"\n",
    "    text = re.sub(r\"\\&nbsp\", \"\", text)\n",
    "    # remove urls\n",
    "    # source: url_extract_pattern from https://uibakery.io/regex-library/url-regex-python\n",
    "    url_extract_pattern = \"https?:\\\\/\\\\/(?:www\\\\.)?[-a-zA-Z0-9@:%._\\\\+~#=]{1,256}\\\\.[a-zA-Z0-9()]{1,6}\\\\b(?:[-a-zA-Z0-9()@:%_\\\\+.~#?&\\\\/=]*)\"\n",
    "    text = re.sub(url_extract_pattern, '', text)\n",
    "    # remvoe \"\\n\"\n",
    "    text = re.sub(r\"[^ ]*\\n\", \"\", text)\n",
    "    # remove file names with commom endings with 4 or 3 digits\n",
    "    text = re.sub(r\"[^ ]*\\..{4}|[^ ]*\\..{3}\", \"\", text)\n",
    "    # remove any refs\n",
    "    text = re.sub(r\"[^ ]*ref\", \"\", text)\n",
    "    # remove -\n",
    "    text = re.sub(r\"-\", \"\", text)\n",
    "    #remove punctuation thats left\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    print(\"regex\")\n",
    "    \n",
    "    # remove stopwords\n",
    "    text = text.split(\" \")\n",
    "    # source: https://stackoverflow.com/questions/5486337/how-to-remove-stop-words-using-nltk-or-python\n",
    "    text = [word for word in text if word not in german_stopwords]\n",
    "    print(\"stopwords\")\n",
    "    \n",
    "    # lemmatization\n",
    "    text_lemma = []\n",
    "\n",
    "    for ix, word in enumerate(text):\n",
    "        doc = nlp(word)\n",
    "        result = ' '.join([x.lemma_ for x in doc]) \n",
    "        text_lemma.append(result)\n",
    "    print(\"lemma\")\n",
    "    \n",
    "    final = [gensim.utils.simple_preprocess(word, deacc = True) for word in text_lemma]\n",
    "    print(\"final\")\n",
    "    \n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876ae892",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1441882e",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://de.wikipedia.org/w/api.php\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9487adfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "german_stopwords = stopwords.words(\"german\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b6236171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl gesammelter Exzellenter Artikel: 2796\n"
     ]
    }
   ],
   "source": [
    "# request excellent arictles from german wikipedia via wiki api (10 at a time)\n",
    "S = requests.Session()\n",
    "\n",
    "params = {\n",
    "    \"action\": \"query\",\n",
    "    \"prop\": \"revisions\",\n",
    "    \"rvprop\": \"content\",\n",
    "    \"rvslots\": \"*\",\n",
    "    \"format\": \"json\",\n",
    "    \"formatversion\": 2,\n",
    "    \"srsearch\": \"incategory:Wikipedia:Exzellent\",\n",
    "    \"list\": \"search\",\n",
    "    \"sroffset\": 0\n",
    "}\n",
    "\n",
    "response = S.get(url = URL, params = params)\n",
    "data = response.json()\n",
    "\n",
    "# get ids from excellent articles\n",
    "ids = []\n",
    "\n",
    "for entry in data[\"query\"][\"search\"]:\n",
    "    ids.append(entry[\"pageid\"])\n",
    "\n",
    "while data.get(\"continue\"):\n",
    "    params.update({\"sroffset\": data[\"continue\"][\"sroffset\"]})\n",
    "    \n",
    "    #print(\"\\n%s\" % (PARAMS))\n",
    "    response = S.get(url = URL, params = params)\n",
    "    data = response.json()\n",
    "    \n",
    "    for entry in data[\"query\"][\"search\"]:\n",
    "        ids.append(entry[\"pageid\"])\n",
    "\n",
    "print(\"Anzahl gesammelter Exzellenter Artikel: %s\" %(len(ids)))\n",
    "\n",
    "#if DATA['query']['search'][0]['title'] == SEARCHPAGE:\n",
    "#    print(\"Your search page '\" + SEARCHPAGE + \"' exists on English Wikipedia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "70e907bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ed25c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# request data to every excellent article in german wikipedia via wikipedia api using pageid\n",
    "params = {\n",
    "    \"action\": \"query\",\n",
    "    \"prop\": \"revisions\",\n",
    "    \"rvprop\": \"content\",\n",
    "    \"rvslots\": \"*\",\n",
    "    \"format\": \"json\",\n",
    "    \"formatversion\": 2,\n",
    "    \"pageids\": 0\n",
    "}\n",
    "\n",
    "data = pd.DataFrame()\n",
    "content = {}\n",
    "\n",
    "for ix, id in enumerate(ids):\n",
    "    update_progress(ix / len(ids))\n",
    "    start = time.time()\n",
    "    params.update({\"pageids\": id})\n",
    "    response = S.get(url = URL, params = params)\n",
    "    page = response.json()\n",
    "    \n",
    "    preprocessed = preprocess(page[\"query\"][\"pages\"][0][\"revisions\"][0][\"slots\"][\"main\"][\"content\"], german_stopwords)\n",
    "    \n",
    "    for word in preprocessed:\n",
    "        if len(word) == 0:\n",
    "            preprocessed.remove(word)\n",
    "        \n",
    "    content.update({id: preprocessed})\n",
    "    end = time.time()\n",
    "    print(\"DUR: %s\" % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8972d910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save requested data in df\n",
    "df = pd.DataFrame(content.items())\n",
    "df = df.rename({0: \"pageid\", 1:\"content\"}, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7ab397e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pageid</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1428</td>\n",
       "      <td>[[dateidanimarca], [xiii], [secolo], [plinio],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2677</td>\n",
       "      <td>[[infobox], [nameamtssprach], [namedeutsch], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1200964</td>\n",
       "      <td>[[weit], [bedeutung], [sehen], [australien], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>880316</td>\n",
       "      <td>[[infobox], [nameamtssprach], [suomen], [tasav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2391</td>\n",
       "      <td>[[land], [bedeutung], [sehen], [indien], [info...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1636</td>\n",
       "      <td>[[sprachefinnisch], [landerfinnland], [schwede...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>3840777</td>\n",
       "      <td>[[infobox], [gemeinde], [art], [wappe], [deu],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>4282822</td>\n",
       "      <td>[[dateipartition], [of], [poland], [drei], [te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>88474</td>\n",
       "      <td>[[dateigerman], [masters], [snooker], [final],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>8736</td>\n",
       "      <td>[[information], [umgang], [vorlage], [sehen], ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pageid                                            content\n",
       "0       1428  [[dateidanimarca], [xiii], [secolo], [plinio],...\n",
       "1       2677  [[infobox], [nameamtssprach], [namedeutsch], [...\n",
       "2    1200964  [[weit], [bedeutung], [sehen], [australien], [...\n",
       "3     880316  [[infobox], [nameamtssprach], [suomen], [tasav...\n",
       "4       2391  [[land], [bedeutung], [sehen], [indien], [info...\n",
       "..       ...                                                ...\n",
       "104     1636  [[sprachefinnisch], [landerfinnland], [schwede...\n",
       "105  3840777  [[infobox], [gemeinde], [art], [wappe], [deu],...\n",
       "106  4282822  [[dateipartition], [of], [poland], [drei], [te...\n",
       "107    88474  [[dateigerman], [masters], [snooker], [final],...\n",
       "108     8736  [[information], [umgang], [vorlage], [sehen], ...\n",
       "\n",
       "[109 rows x 2 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "88aea7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data to csv for faster loading\n",
    "df.to_csv(\"./preprocessed_excellent_article-109.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "80e0cedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = [gensim.utils.simple_preprocess(word, deacc = True) for word in test_page_lemma]\n",
    "\n",
    "id2word = corpora.Dictionary(final)\n",
    "\n",
    "corpus = [id2word.doc2bow(word) for word in final]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e41a28d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "deee4069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.600257403850556"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(ids) * 53.56256318092346) / 60 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cc4d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3108jvsc74a57bd0b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
